{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposition-Based Validation Study\n",
    "\n",
    "\n",
    "In this notebook, use `Proposition`s to validate agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!\n",
      "DISCLAIMER: TinyTroupe relies on Artificial Intelligence (AI) models to generate content. \n",
      "The AI models are not perfect and may produce inappropriate or inacurate results. \n",
      "For any serious or consequential use, please review the generated content before using it.\n",
      "!!!!\n",
      "\n",
      "Looking for default config on: c:\\Users\\pdasilva\\repos\\TinyTroupe\\examples\\scratch\\..\\..\\tinytroupe\\utils\\..\\config.ini\n",
      "Found custom config on: c:\\Users\\pdasilva\\repos\\TinyTroupe\\examples\\scratch\\config.ini\n",
      "\n",
      "=================================\n",
      "Current TinyTroupe configuration \n",
      "=================================\n",
      "[OpenAI]\n",
      "api_type = openai\n",
      "azure_api_version = 2023-05-15\n",
      "model = gpt-4o-mini\n",
      "reasoning_model = o3-mini\n",
      "embedding_model = text-embedding-3-small\n",
      "max_tokens = 16000\n",
      "temperature = 1.2\n",
      "freq_penalty = 0.0\n",
      "presence_penalty = 0.0\n",
      "timeout = 60\n",
      "max_attempts = 5\n",
      "waiting_time = 0\n",
      "exponential_backoff_factor = 5\n",
      "reasoning_effort = high\n",
      "cache_api_calls = False\n",
      "cache_file_name = openai_api_cache.pickle\n",
      "max_content_display_length = 1024\n",
      "\n",
      "[Simulation]\n",
      "parallel_agent_generation = True\n",
      "parallel_agent_actions = True\n",
      "rai_harmful_content_prevention = True\n",
      "rai_copyright_infringement_prevention = True\n",
      "\n",
      "[ActionGenerator]\n",
      "max_attempts = 2\n",
      "enable_quality_checks = False\n",
      "enable_regeneration = False\n",
      "enable_direct_correction = False\n",
      "continue_on_failure = True\n",
      "quality_threshold = 2\n",
      "\n",
      "[Logging]\n",
      "loglevel = WARNING\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from tinytroupe.examples import *\n",
    "from tinytroupe.environment import TinyWorld\n",
    "from tinytroupe.factory import TinyPersonFactory\n",
    "from tinytroupe.steering import Intervention\n",
    "from tinytroupe.validation import propositions\n",
    "from tinytroupe.validation import TinyPersonValidator\n",
    "\n",
    "from tinytroupe.experimentation import Proposition, InPlaceExperimentRunner\n",
    "from tinytroupe import control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#researcher = TinyPersonFactory().generate_person(\"A professional market researcher.\")\n",
    "#researcher.save_specification(f\"./{researcher.name}_(Market_Researcher).agent.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 16:16:21,534 - tinytroupe - WARNING - Configuration file './experiment_config_11.json' exists and was loaded successfully. If you are trying to fully rerun the experiments, delete it first.\n"
     ]
    }
   ],
   "source": [
    "experiment_runner = InPlaceExperimentRunner(\"./experiment_config_11.json\")  # Set parallel=False to avoid pickling errors\n",
    "\n",
    "experiment_runner.add_experiment(\"A\")\n",
    "experiment_runner.add_experiment(\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_runner.activate_next_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propositions of interest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "persona_adherene_proposition = Proposition(\"THE AGENT ADHERES TO THE PERSONA SPECIFICATION: the agent behavior seen during the simulation is what is expected from the agent's persona specification.\", include_personas=True)\n",
    "\n",
    "selfconsistency_proposition = Proposition(\"THE AGENT IS SELF-CONSISTENT: the agent never behaves in contradictory or inconsistent ways.\", include_personas=False)\n",
    "\n",
    "divergence_proposition = \\\n",
    "    Proposition(\"\"\"\n",
    "                AGENTS DIVERGE FROM ONE ANOTHER.\n",
    "                As the simulation progresses, the agents' behaviors diverge from one another,\n",
    "                instead of becoming more similar. This includes what they think, what they say and what they do. The topics discussed become\n",
    "                more varied at the end of the simulation than at the beginning. Discussions do not converge to a single topic or perspective\n",
    "                at the end.\n",
    "                \"\"\", \n",
    "                include_personas=False)\n",
    "\n",
    "fluency_proposition = \\\n",
    "    Proposition(\\\n",
    "        \"\"\"\n",
    "        THE AGENT IS FLUENT. During the simulation, the agent's thinks and speaks fluently. This means that:\n",
    "          - The agent don't repeat the same thoughts or words over and over again.\n",
    "          - The agents don't use overly formulaic language.\n",
    "          - The agent don't use overly repetitive language.\n",
    "          - The agent's words sound natural and human-like.\n",
    "        \"\"\",\n",
    "        include_personas=True)\n",
    "\n",
    "task_completion_proposition = \\\n",
    "    Proposition(\\\n",
    "        \"\"\"\n",
    "        THE AGENT COMPLETES THE GIVEN TASK. \n",
    "\n",
    "        Given the following task: \"{{task_description}}\"\n",
    "        \n",
    "        The agent completes the task by the end of the simulation. \n",
    "        \n",
    "        This means that:\n",
    "          - If the task requires the agent to discuss or talk about something, the agent does so.\n",
    "          - If the task requires the agent to think about something, the agent does so.\n",
    "          - If the task requires the agent to do something via another action, the agent does so.\n",
    "          - If the task requires the agent to adopt some specific variations of behavior, the agent does so.\n",
    "          - If the task includes other specific requirements, the agent observes them.\n",
    "        \"\"\",\n",
    "        include_personas=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personas_briefings = [\n",
    "#    \"A very picky, stingy, hard to please, customer. Never buys anthing new. Don't like anything. Always complains about everything. Is never enthusiastic, never nice, never happy at all about anything.\",\n",
    "#    \"A very wealthy individual, who only buys the most expenstive things. He hates good deals because it makes him look poor. Very insecure, so is always, invariably, with no exception, showing off.\",  \n",
    "#    \"A very poor individual, who only buys the cheapest things. Will never spend anything unless it is absolutely necessary for survival.\",\n",
    "#]\n",
    "#factory = TinyPersonFactory()\n",
    "## instantiate the agents\n",
    "#\n",
    "#people = []\n",
    "#for persona_briefing in personas_briefings:\n",
    "#    person = factory.generate_person(persona_briefing)\n",
    "#\n",
    "#    score, justification = TinyPersonValidator.validate_person(person, expectations=persona_briefing, \n",
    "#                                                               include_agent_spec=False, max_content_length=None)\n",
    "#    \n",
    "#    print(f\"VALIDATION: {score} - {justification}\")\n",
    "#    print(person.minibio())\n",
    "#    print(\"\\n\\n\")\n",
    "#    people.append(person)\n",
    "#\n",
    "## save agents\n",
    "#for i, person in enumerate(people):\n",
    "#    person.save_specification(f\"./{person.name}.agent.json\")\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily Carter is a 42 year old Customer Service Representative, American, currently living in Cleveland, Ohio, USA. Emily Carter's personality is marked by a critical lens through which she views the world, often leading her to express dissatisfaction with her surroundings. Her interests lean towards thriftiness, as she enjoys shopping for second-hand items and finds solace in familiar routines, avoiding new experiences and crowded places. While she may come off as cold and unapproachable, her relationships with her sister Sarah and coworker Tom reveal a shared understanding of her critical nature, even if they sometimes attempt to encourage a more positive outlook. Despite her pessimism, Emily occasionally finds small victories in her daily life, such as successfully navigating customer service protocols or returning a faulty item, which provide her with fleeting moments of satisfaction.\n",
      "Michael Thompson is a 45 year old CEO, American, currently living in Beverly Hills, California, USA. Michael Thompson is not only a successful CEO but also a dynamic personality who thrives on ambition and competition. His interests in luxury travel and fine dining reflect his desire for the extraordinary, while his collection of rare art pieces showcases his appreciation for exclusivity and culture. Despite his charming exterior, he often grapples with insecurities about his status, driving him to constantly seek validation through networking and high-profile events. Fluent in French and Italian, he leverages his language skills to enhance his international business dealings, further solidifying his position in the luxury market.\n",
      "Sophia Mitchell is a 42 year old Part-time Cleaner, American, currently living in Cleveland, Ohio. Sophia Mitchell is a resilient individual who navigates the challenges of her life with resourcefulness and determination. Despite her financial anxieties, she finds joy in simple pleasures, such as cooking for her children and tending to her small garden, which reflects her nurturing nature. Her practical approach to life is evident in her ability to seek out discounts and manage her household efficiently, even as she grapples with feelings of isolation and pessimism. Sophia's strong sense of family drives her to prioritize her children's well-being, often sacrificing her own needs to ensure they have a stable and loving environment.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# avoid displaying the communication, to make the output cleaner for eval\n",
    "TinyPerson.communication_display = True\n",
    "\n",
    "# load agents\n",
    "people = TinyPerson.load_specifications_from_folder(\"./picky_customers_2\")\n",
    "\n",
    "# filter to make it go faster?\n",
    "#people = people[:5]\n",
    "\n",
    "# print minibios \n",
    "for person in people:\n",
    "    print(person.minibio())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher = TinyPerson.load_specification(\"./Daniel Harris (Market Researcher).agent.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running experiment {experiment_runner.get_active_experiment()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_runner.get_active_experiment() == \"A\":    \n",
    "    for person in people:\n",
    "       person.action_generator.enable_quality_checks = False\n",
    "\n",
    "elif experiment_runner.get_active_experiment() == \"B\":\n",
    "    for person in people:\n",
    "        person.action_generator.enable_quality_checks = True # quality checks for this experiment\n",
    "        person.action_generator.max_attempts = 10\n",
    "        person.action_generator.enable_regeneration = True\n",
    "        person.action_generator.quality_threshold = 8\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_group_battery(agents, discussion_objectives, agent_propositions, environment_propositions, \n",
    "                        simulation_steps=10): \n",
    "    \n",
    "    agent_propositions_scores = {}\n",
    "    environment_propositions_scores = {}\n",
    "\n",
    "    # Add intervention to prevent agents from being too quiet.\n",
    "    interventions = []\n",
    "    for agent in agents:\n",
    "        intervention = \\\n",
    "            Intervention(agent)\\\n",
    "                .set_propositional_precondition(propositions.quiet_recently)\\\n",
    "                .set_effect(lambda target: target.think(\"\"\"\n",
    "                                                        I will say something now, I've been too quiet for a while. If I am uncomfortable, \n",
    "                                                        or can't think of a proper response,\n",
    "                                                        I can always say something like \"I don't want to talk about this\",\n",
    "                                                        or propose another topic.\n",
    "                                                        \"\"\"))\\\n",
    "                                                        \n",
    "\n",
    "        interventions.append(intervention)\n",
    "\n",
    "    \n",
    "    world = TinyWorld(f\"Focus group\", agents=agents, interventions=interventions)\n",
    "   \n",
    "\n",
    "    # Participants introduce themselves\n",
    "    world.broadcast(\"\"\"\n",
    "            Hello everyone! Today we will be having some discussion sessions, about one or more topics. \n",
    "            I'll give you a situation and/or a task, and you will discuss with each other to address it.\n",
    "            You must behave as you really are, revealing your true self.\n",
    "            You can be honest and open, and you can also be critical of each other.\n",
    "                    \n",
    "            But before we start, let's take a moment to introduce ourselves.\n",
    "            What is your job and what are some major problems you face in your work and personal life? \n",
    "            What are major challenges for your industry as a whole, and in your personal life. \n",
    "            Don't discuss solutions yet, just the problems you face.\n",
    "            \"\"\")\n",
    "    world.run(1)\n",
    "\n",
    "    # loop over objectives\n",
    "    for objective in discussion_objectives:\n",
    "\n",
    "        print(f\"Discussion objective: {objective}\")\n",
    "        print(f\"Agents in the discussion: {[person.name for person in world.agents]}\")\n",
    "\n",
    "        # clear the episodic memory of all agents\n",
    "        for person in world.agents:\n",
    "            person.clear_episodic_memory()\n",
    "\n",
    "        # now to the discussions\n",
    "        world.broadcast(f\"\"\"\n",
    "                Folks, now {objective}\n",
    "                    \n",
    "                Please start the discussion now.\n",
    "                \"\"\")\n",
    "\n",
    "        world.run(simulation_steps)\n",
    "\n",
    "        # evaluate the propositions\n",
    "        for k, proposition in environment_propositions.items():\n",
    "            result = proposition.score(world, claim_variables={\"task_description\": objective}, \n",
    "                                        return_full_response=True)\n",
    "\n",
    "            if k not in environment_propositions_scores:\n",
    "                environment_propositions_scores[k] = []\n",
    "            environment_propositions_scores[k].append(result[\"value\"])\n",
    "\n",
    "            print(result)\n",
    "        \n",
    "        for k, proposition in agent_propositions.items():\n",
    "            for person in world.agents:\n",
    "                result = proposition.score(person, return_full_response=True)\n",
    "                \n",
    "                if k not in agent_propositions_scores:\n",
    "                    agent_propositions_scores[k] = []\n",
    "                agent_propositions_scores[k].append(result[\"value\"])\n",
    "\n",
    "                print(result)\n",
    "    \n",
    "        world.broadcast(\"\"\"\n",
    "                Ok, great. Now let's move to the next discussion theme.\n",
    "                \"\"\")\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    return agent_propositions_scores, environment_propositions_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_research_battery(researcher, agents, proposals, agent_propositions, environment_propositions, \n",
    "                            repetitions=1, simulation_steps=10): \n",
    "    \n",
    "    agent_propositions_scores = {}\n",
    "    environment_propositions_scores = {}\n",
    "\n",
    "    print(\"Researcher minibio:\", researcher.minibio())\n",
    "    print(\"Proposals:\", proposals)\n",
    "\n",
    "    experiments_count = 0\n",
    "    total_expected_experiments = len(proposals) * repetitions * len(agents)\n",
    "\n",
    "    # loop over proposals\n",
    "    for proposal in proposals:\n",
    "        for i in range(repetitions):\n",
    "            for customer in agents:\n",
    "                print(\"\\n############## STARTING A NEW RESEARCH SESSION #################\")\n",
    "                print(f\"Overall experiment number: {experiments_count+1} / {total_expected_experiments}\")\n",
    "                print(f\"Proposal: {proposal}\")\n",
    "                print(f\"Trial number: {i+1}\")\n",
    "                print(f\"Customer: {customer.name}\")\n",
    "                print(f\"Biography: {customer.minibio()}\")\n",
    "\n",
    "                world = TinyWorld(agents= [researcher, customer])\n",
    "\n",
    "                # clear the episodic memory of all agents\n",
    "                for person in world.agents:\n",
    "                    person.clear_episodic_memory()\n",
    "\n",
    "                    \n",
    "                researcher.listen(f\"\"\"\n",
    "                            You are goint to run a market research session with a person.\n",
    "                            Your objective is to determine whether the person would buy the following product or service, and why:\n",
    "                            \n",
    "                                \"{proposal}\"\n",
    "                        \n",
    "                            \"\"\")\n",
    "                \n",
    "                customer.listen(\\\n",
    "                    \"\"\"\n",
    "                    You are going to be interviewed by a market researcher about a product or service.\n",
    "                    Wait for his questions and answer them honestly.\n",
    "                    \"\"\"\n",
    "                    )\n",
    "                                \n",
    "\n",
    "                # now to the discussions\n",
    "                world.broadcast(f\"\"\"\n",
    "                        Begin the market research session.\n",
    "                        \"\"\")\n",
    "                world.make_everyone_accessible()\n",
    "                world.run(simulation_steps)\n",
    "                experiments_count += 1\n",
    "\n",
    "                # evaluate the propositions\n",
    "                for k, proposition in environment_propositions.items():\n",
    "                    result = proposition.score(world, claim_variables={\"task_description\": f\"A market research session was run about: {proposal}.\"}, \n",
    "                                                return_full_response=True)\n",
    "                    \n",
    "                    if k not in environment_propositions_scores:\n",
    "                        environment_propositions_scores[k] = []\n",
    "                    environment_propositions_scores[k].append(result[\"value\"])\n",
    "\n",
    "                    print(result)\n",
    "\n",
    "                for k, proposition in agent_propositions.items():\n",
    "                    result = proposition.score(customer, return_full_response=True)\n",
    "                    \n",
    "                    if k not in agent_propositions_scores:\n",
    "                        agent_propositions_scores[k] = []\n",
    "                    agent_propositions_scores[k].append(result[\"value\"])\n",
    "\n",
    "                    print(result)\n",
    "\n",
    "\n",
    "    return agent_propositions_scores, environment_propositions_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not experiment_runner.has_finished_all_experiments():\n",
    "    agent_propositions_scores, environment_propositions_scores = \\\n",
    "        market_research_battery(\\\n",
    "            researcher=researcher,\n",
    "            agents=people,\n",
    "            proposals=\n",
    "            [\n",
    "            \"Bottled gazpacho to be sold in supermarkets\",\n",
    "            \"An app for luxury travel, particularly for places where kids are not allowed\",\n",
    "            \"A subscription to discount coupons for supermarkets, ensuring always the lowest prices, even if at the cost of quality\",\n",
    "            \"A subscription to a service that sends you a new, expensive, luxury item every month, without you having to choose it.\",\n",
    "            ],\n",
    "\n",
    "            agent_propositions={\n",
    "                \"Persona Adherence\": persona_adherene_proposition,\n",
    "                \"Self-consistency\": selfconsistency_proposition,\n",
    "                \"Fluency\": fluency_proposition\n",
    "            },\n",
    "            environment_propositions={\n",
    "                #\"Task Completion\": task_completion_proposition,\n",
    "                #\"Divergence\": divergence_proposition\n",
    "            },\n",
    "            repetitions=5,\n",
    "            simulation_steps=4\n",
    "        )\n",
    "\n",
    "    pprint(\"AGENT PROPOSITIONS SCORES\")\n",
    "    pprint(agent_propositions_scores)\n",
    "    print(\"\\n\\n\")\n",
    "    pprint(\"ENVIRONMENT PROPOSITIONS SCORES\")\n",
    "    pprint(environment_propositions_scores)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average scores and sd per proposition (use some well-known lib to compute statistics)\n",
    "def compute_average_scores(scores):\n",
    "    average_scores = {}\n",
    "    for k, v in scores.items():\n",
    "        average_scores[k] = {\n",
    "            \"mean\": sum(v) / len(v),\n",
    "            \"sd\": pd.Series(v).std(),\n",
    "            \"n\": len(v)\n",
    "        }\n",
    "    return average_scores\n",
    "\n",
    "def plot_scores(propositions_scores):\n",
    "    pprint(propositions_scores)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    propositions_scores_stats = compute_average_scores(propositions_scores)\n",
    "\n",
    "    # build a pandas dataframe with average scores per proposition\n",
    "    df = pd.DataFrame(propositions_scores_stats).T\n",
    "    df = df.rename(columns={\"mean\": \"Average Score\", \"sd\": \"Standard Deviation\", \"n\": \"Count\"})\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\"index\": \"Proposition\"})\n",
    "    \n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_runner.get_active_experiment() == \"A\":\n",
    "    combined_scores = {**agent_propositions_scores, **environment_propositions_scores}\n",
    "    experiment_runner.add_experiment_results(\"A\", combined_scores) \n",
    "    \n",
    "    plot_scores(combined_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_runner.get_active_experiment() == \"B\":\n",
    "    combined_scores = {**agent_propositions_scores, **environment_propositions_scores}\n",
    "    experiment_runner.add_experiment_results(\"B\", combined_scores)\n",
    "    \n",
    "    plot_scores(combined_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All experiments have been finished.\n",
      "STATISTICTS: Control vs\n",
      "{'B': {'Fluency': {'confidence_interval': (-1.2302320895631436,\n",
      "                                           0.4635654228964762),\n",
      "                   'confidence_level': 0.95,\n",
      "                   'control_mean': 5.4,\n",
      "                   'control_sample_size': 60,\n",
      "                   'degrees_of_freedom': 117.28397114591029,\n",
      "                   'effect_size': -0.16365784645203554,\n",
      "                   'mean_difference': -0.38333333333333375,\n",
      "                   'p_value': 0.37188020759304397,\n",
      "                   'percent_change': -7.098765432098772,\n",
      "                   'significant': False,\n",
      "                   't_statistic': 0.896390942144967,\n",
      "                   'test_type': 'Welch t-test (unequal variance)',\n",
      "                   'treatment_mean': 5.016666666666667,\n",
      "                   'treatment_sample_size': 60},\n",
      "       'Persona Adherence': {'confidence_interval': (0.46621596556732037,\n",
      "                                                     1.633784034432681),\n",
      "                             'confidence_level': 0.95,\n",
      "                             'control_mean': 7.033333333333333,\n",
      "                             'control_sample_size': 60,\n",
      "                             'degrees_of_freedom': 100.16264476330167,\n",
      "                             'effect_size': 0.6514832522227291,\n",
      "                             'mean_difference': 1.0500000000000007,\n",
      "                             'p_value': 0.0005532153485800656,\n",
      "                             'percent_change': 14.928909952606645,\n",
      "                             'significant': True,\n",
      "                             't_statistic': -3.5683207307921636,\n",
      "                             'test_type': 'Welch t-test (unequal variance)',\n",
      "                             'treatment_mean': 8.083333333333334,\n",
      "                             'treatment_sample_size': 60},\n",
      "       'Self-consistency': {'confidence_interval': (-0.7774615245146891,\n",
      "                                                    0.010794857848023365),\n",
      "                            'confidence_level': 0.95,\n",
      "                            'control_mean': 4.583333333333333,\n",
      "                            'control_sample_size': 60,\n",
      "                            'degrees_of_freedom': 116.2931039848526,\n",
      "                            'effect_size': -0.35169759458136735,\n",
      "                            'mean_difference': -0.38333333333333286,\n",
      "                            'p_value': 0.05650412414058973,\n",
      "                            'percent_change': -8.363636363636354,\n",
      "                            'significant': False,\n",
      "                            't_statistic': 1.926327059725216,\n",
      "                            'test_type': 'Welch t-test (unequal variance)',\n",
      "                            'treatment_mean': 4.2,\n",
      "                            'treatment_sample_size': 60}}}\n",
      "{'Fluency': [3,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             3,\n",
      "             8,\n",
      "             6,\n",
      "             3,\n",
      "             8,\n",
      "             6,\n",
      "             3,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             3,\n",
      "             8,\n",
      "             6,\n",
      "             3,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             3,\n",
      "             8,\n",
      "             6,\n",
      "             3,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             6,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             3,\n",
      "             6,\n",
      "             6,\n",
      "             3,\n",
      "             7,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             5,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6],\n",
      " 'Persona Adherence': [6,\n",
      "                       6,\n",
      "                       6,\n",
      "                       8,\n",
      "                       6,\n",
      "                       9,\n",
      "                       6,\n",
      "                       6,\n",
      "                       6,\n",
      "                       8,\n",
      "                       9,\n",
      "                       6,\n",
      "                       8,\n",
      "                       6,\n",
      "                       9,\n",
      "                       8,\n",
      "                       9,\n",
      "                       0,\n",
      "                       6,\n",
      "                       9,\n",
      "                       3,\n",
      "                       4,\n",
      "                       9,\n",
      "                       3,\n",
      "                       9,\n",
      "                       9,\n",
      "                       3,\n",
      "                       6,\n",
      "                       9,\n",
      "                       6,\n",
      "                       8,\n",
      "                       8,\n",
      "                       9,\n",
      "                       6,\n",
      "                       6,\n",
      "                       9,\n",
      "                       9,\n",
      "                       6,\n",
      "                       9,\n",
      "                       6,\n",
      "                       6,\n",
      "                       9,\n",
      "                       8,\n",
      "                       6,\n",
      "                       9,\n",
      "                       9,\n",
      "                       8,\n",
      "                       6,\n",
      "                       8,\n",
      "                       9,\n",
      "                       8,\n",
      "                       6,\n",
      "                       9,\n",
      "                       6,\n",
      "                       6,\n",
      "                       8,\n",
      "                       6,\n",
      "                       6,\n",
      "                       9,\n",
      "                       6],\n",
      " 'Self-consistency': [4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      9,\n",
      "                      6,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      6,\n",
      "                      8,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      6,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      3,\n",
      "                      4,\n",
      "                      4,\n",
      "                      3,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proposition</th>\n",
       "      <th>Average Score</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Persona Adherence</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>1.921922</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-consistency</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>1.154089</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fluency</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.248917</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Proposition  Average Score  Standard Deviation  Count\n",
       "0  Persona Adherence       7.033333            1.921922   60.0\n",
       "1   Self-consistency       4.583333            1.154089   60.0\n",
       "2            Fluency       5.400000            2.248917   60.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fluency': [2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             3,\n",
      "             8,\n",
      "             5,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             5,\n",
      "             2,\n",
      "             7,\n",
      "             4,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             6,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             6,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             6,\n",
      "             4,\n",
      "             1,\n",
      "             8,\n",
      "             5,\n",
      "             1,\n",
      "             6,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             6,\n",
      "             2,\n",
      "             8,\n",
      "             4],\n",
      " 'Persona Adherence': [8,\n",
      "                       9,\n",
      "                       6,\n",
      "                       8,\n",
      "                       6,\n",
      "                       6,\n",
      "                       8,\n",
      "                       6,\n",
      "                       8,\n",
      "                       9,\n",
      "                       6,\n",
      "                       9,\n",
      "                       9,\n",
      "                       8,\n",
      "                       9,\n",
      "                       8,\n",
      "                       9,\n",
      "                       6,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       6,\n",
      "                       9,\n",
      "                       9,\n",
      "                       6,\n",
      "                       8,\n",
      "                       9,\n",
      "                       6,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       6,\n",
      "                       9,\n",
      "                       9,\n",
      "                       8,\n",
      "                       9,\n",
      "                       8,\n",
      "                       6,\n",
      "                       8,\n",
      "                       9,\n",
      "                       9,\n",
      "                       8,\n",
      "                       6,\n",
      "                       6,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       9,\n",
      "                       8,\n",
      "                       9,\n",
      "                       8,\n",
      "                       6],\n",
      " 'Self-consistency': [4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      6,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      3,\n",
      "                      6,\n",
      "                      6,\n",
      "                      3,\n",
      "                      6,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      6,\n",
      "                      3,\n",
      "                      4,\n",
      "                      4,\n",
      "                      3,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      4,\n",
      "                      2,\n",
      "                      4,\n",
      "                      3,\n",
      "                      3,\n",
      "                      3,\n",
      "                      4,\n",
      "                      3,\n",
      "                      4,\n",
      "                      4,\n",
      "                      2,\n",
      "                      4,\n",
      "                      4,\n",
      "                      6,\n",
      "                      4,\n",
      "                      4]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proposition</th>\n",
       "      <th>Average Score</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Persona Adherence</td>\n",
       "      <td>8.083333</td>\n",
       "      <td>1.225321</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-consistency</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.021796</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fluency</td>\n",
       "      <td>5.016667</td>\n",
       "      <td>2.432071</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Proposition  Average Score  Standard Deviation  Count\n",
       "0  Persona Adherence       8.083333            1.225321   60.0\n",
       "1   Self-consistency       4.200000            1.021796   60.0\n",
       "2            Fluency       5.016667            2.432071   60.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if experiment_runner.has_finished_all_experiments():\n",
    "    print(\"All experiments have been finished.\")\n",
    "    print(f\"STATISTICTS: Control vs\")\n",
    "    pprint(experiment_runner.run_statistical_tests(control_experiment_name='A'))\n",
    "\n",
    "    # plot scores of both experiments\n",
    "    experiment_a_scores = experiment_runner.get_experiment_results(\"A\")\n",
    "    experiment_b_scores = experiment_runner.get_experiment_results(\"B\")\n",
    "    \n",
    "    \n",
    "    plot_scores(experiment_a_scores)\n",
    "    plot_scores(experiment_b_scores)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Not all experiments have been finished. RESTART AND RERUN.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
